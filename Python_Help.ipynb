{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Some stuff about WQU: \n",
    "Jupyter: always duplicate the notebooks before tampering. You should get 0.9 everywhere to pass. Depending on the course, you might get bonus points. \n",
    "Note that some exercises require to pass a function. \n",
    "Style of questions available on the discussion board: how to turn a dict into tuples? \n",
    "Always include code + plain English description + tags (dict, pw, ...) \n",
    "Update the question with an answer, don't answer in the comments. Format properly.'''\n",
    "\n",
    "\n",
    "#Programming and Python fundamentals \n",
    "#Conda tips\n",
    "conda update \n",
    "conda install nomPackage \n",
    "conda update anaconda \n",
    "conda list \n",
    "\n",
    "#Jupyter tips \n",
    "Title: ## \n",
    "Keyboard functions shown in the menu \n",
    "Command mode (highlighted in blue): navigate cells with arrows, create/delete cells\n",
    "Execution: ctrl + enter \n",
    "Execution + creation of new cell: shift + enter \n",
    "Shift from one mode to another: hit Escape or enter\n",
    "Enter edit mode: Enter\n",
    "Change cell to markdown: M \n",
    "Change cell to raw: R \n",
    "Change cell to code: Y \n",
    "Select cell above: K \n",
    "Select cell below: J \n",
    "Insert cell above: A \n",
    "Insert cell below: B, +\n",
    "\n",
    "#Introduction to programming\n",
    "'''The interpreter will only show the last result that was evaluated.\n",
    "Tracebacks shows where the error was encountered. Arguments only have meanings within the function (LGI).\n",
    "Be cautious about functions using the general state of the program (don't refer to variables not passed as variables\n",
    "Every keyword is highlighted in green and shouldn't be modified (e.g. def) \n",
    "Documentation always includes stuff about args, calculation, returned values. \n",
    "Exceptions: every code should be able to handle exceptions - use try/except/finally'''\n",
    "Import the zen of Python: import this \n",
    "ExceptionType: AssertionError, IndexError (index sequence out of range), SyntaxError,\n",
    " TabError (inconsistent indentation), ValueError (function gets correct type of argument but value is incoherent)\n",
    "\n",
    "Handling Exceptions: \n",
    "\t\n",
    "\tassert pow(2,6) == 4, 'Error in the assertion'\n",
    "\t\n",
    "\tif condition: \n",
    "\t\traise TypeError, 'The word must be a string'\n",
    "\t\n",
    "\ttry: \n",
    "\t\tfile = open('filename.txt')\n",
    "\t\tfile.write('Python is awesome')\n",
    "\texcept ExceptionType: \n",
    "\t\tprint('An error has occured when writing to the file')\n",
    "\tfinally: \n",
    "\t\tfile.close()\n",
    "\n",
    "\tdef check_ana(word1,word2): \n",
    "\t\tassert type(word1) == str, 'Must be a str'\n",
    "\t\tassert type(word2) == str, 'Must be a str'\n",
    "\t\treturn sorted(word1) == sorted(word2) \n",
    "\n",
    "Comments: '''... ''' / # \n",
    "Insert apostrophe in string: \\t \n",
    "Variables: has_dog = True, False, not True\n",
    "Round float: round(nb, ndigits)\n",
    "Find vartype: type(my_variable)\n",
    "Print nothing: print(None)\n",
    "String interpolation: '{}'.format(my_age+10)\n",
    "Variable globale: global nomVariable\n",
    "Laytag: $$ f(x) = 2 $$ #Writes in proper math style\n",
    "Puissance: ** / pow(variable_to_pow,power)\n",
    "CheckEven: x%2 == 0\n",
    "Reste de la division/modulo: 5%3 returns 2 \n",
    "Format faster: print('First %d Fibonacci' %m) will replace %d by value of m, %s by a string\n",
    "For i in liste: for i in [1,5,7]\n",
    "Range: range(10) returns 0,...,9\n",
    "Add counter: += 1\n",
    "Input: msg = input('Want to quit?')\n",
    "Get division and rest in tuple: divmod(numerator, denominator) #Returns (num//dem, num%dem)\n",
    "Lambda: sum = lambda a,b,c: a+b+c / sum(1,2,3) returns 6 #Very useful with map/lists/dicts, create custom fct in a one_liner \n",
    "Recursive functions: factorials / Fibonacci\n",
    "\t\n",
    "\tdef fact(n): \n",
    "\t\tif n == 1: \n",
    "\t\t\treturn n \n",
    "\t\telse: \n",
    "\t\t\treturn n*fact(n-1)\n",
    "\n",
    "\tTurn input str function into actionable function \n",
    "\t#Input is x,k then x**3+x**2+x+1 - and we need to test if str_funct(x) == k\n",
    "\txn,k = list(map(int, input().split()))\n",
    "\tcmd = input().replace('x',str(xn))\n",
    "\tprint(eval(cmd)==k) #using eval forces the exec of the str function\n",
    "\n",
    "Enumerate: enumerate(iterable, start) returns each iteration + counter, initialized at start. \n",
    "Quick way to multiply liste: [0]*5 = [0,0,0,0,0]\n",
    "Function Closure: define a function inside a function, ex one that will raise the nb to some exponent, but we do not know which at the time\n",
    "Setting Default For Args: def print(eat= True, sleep=True) Used in a complex function with many inputs, while maintaining ease of use. Allows to include a smaller nb of arguments than the ones that were defined. \n",
    "Variable Nb Args_Tuple: def print_args(*args) fait passer un tuple de longueur variable en argument \n",
    "Variable Nb Args_Dictionary: def print_args(**kwargs) où kwargs désigne le dictionnaire\n",
    "Keyword Args: def pow(number = x, power = y) permet de call la fcntion en listant les args ds le désordre\n",
    "Specify Arg Type: def funct(name: str)\n",
    "Format floats: \"%.2f\" % 1.2399 returns 1.23 #See format float cheat sheet \n",
    "Capitalize string: str.capitalize()\n",
    "Find position of substring: str.find('substring', index_start, index_end) #returns first index at which it is found\n",
    "Find position of substring from the end: str.rfind('substring') #gives the last index \n",
    "Replace word with another: str.replace('word_replaced','replacement')\n",
    "Find if any element observe a condition: any([condition]) returns True or False\n",
    "Find if all elements observe a condition: all([condition])\n",
    "Eval: force execution of a function stored in a variable. E.g. x = print(3+5) / eval(x) returns 8 #No need to use print\n",
    "\t\n",
    "\tAll/Any: \n",
    "\tN = int(input())\n",
    "\tlnb = list(map(lambda x: int(x), str(input()).split())) | [int(x) for x in liste]\n",
    "\tprint(all([ele>0 for ele in lnb]) and any([str(ele) == str(ele)[::-1] for ele in lnb]))\n",
    "\n",
    " \tBeware: \n",
    "\tprint(50 > 0) returns False | True and True returns True | True and False returns False |\n",
    "\tWhile requires counter update, for animal in animaux does not\n",
    "\n",
    "\n",
    "#Data Structures\n",
    "#Containers are heterogeneous, datasets can be represented in various dstructures (list, tuples, set, dict)\n",
    "#RSI: indicateur avancé pour analyse: H = (H+B)*100 où H = moyenne mobile exponentielle des hausses au cours des n derniers jours (MMMEt = Prixt*A + MMEt-1*(1-A))\n",
    "#Où B = valeur absolue de la MME des baisses au cours des n derniers cours. Le RSI sert à repérer la puissance de un mvt. \n",
    "#MME = moyenne mobile exponentielle\n",
    "# Strings are immutable (cannot be reassigned), can be sorted, are ordered, can be sliced\n",
    "\n",
    "#Strings\n",
    "String validators: \n",
    "- str.isalnum() checks if all the characters of a string are alphanumeric\n",
    "- str.isalpha() checks if characters are all alphabetical\n",
    "- str.isdigit() checks if characters are all digit\n",
    "- str.islower() \n",
    "- str.isupper()\n",
    "Split while conserving varying whitespaces: import re / re.split(r'(\\s+)', line)\n",
    "Split while conserving various dtypes:  [int(i) if i.isdigit() else i for i in s.split('|')]\n",
    "Text wrap: to split a string into several subs of max_length: import textwrap / textwrap.wrap(text_to_wrap, max_length) returns a list with split text\n",
    "Wrap and fill: to print each of the sub onto a different line: textwrap.fill(text, max_length)\n",
    "Align string left: str.ljust(width,('-')) #fills right side with - over defined width \n",
    "Align string center: str.center(width,'-')\n",
    "Align string ight: str.rjust(width,'-')\n",
    "Find if str start with smth: str.startswith(letter) \n",
    "\n",
    "\tPalindromes: str(n) == str(n)[::-1]\n",
    "\n",
    "#Lists\n",
    "#Lists can be heterogeneous, are always ordered (printed the way nbs were added to the list)\n",
    "# You can unpack a list (see tuples) to separate the contents. ValueError if not enough variables to unpack.\n",
    "# You can't add a scalar to a list without loop - use numpy instead \n",
    "Is empty list (ptnc): (not liste_to_check) returns True\n",
    "List Comprehension: [number for number in list_of-numbers if is_prime(number)] #Will add in list all the numbers verifying the condition \n",
    "Append to liste: liste.append() \n",
    "Concatenate list: liste.extend(liste2)/  liste1+liste2 #Append doesn't work w/ lists\n",
    "Remove: list.remove(object_to_remove) #Removes first instance of that object in the list, whatever the pos \n",
    "Slice: liste[0,4] / liste[3:] / liste[-100::] to count from the end of the list backwards. Returns the 100 last elements, starting with the last one. \n",
    "Get the last 3 elements; liste[-3:]\n",
    "Quickly duplicate: liste*2 / [0]*5\n",
    "Removing items: liste.pop(indexOfItemToPop) / del liste[posItemToDel] \n",
    "Copy: liste.copy()\n",
    "Spot element: if 'Google' in liste:\n",
    "Reverse: liste.reverse()\n",
    "Sort: liste.sort()\n",
    "Clear: liste.clear()\n",
    "Add element at specified position in liste: liste.insert(index, object) #insert an object before the index  \n",
    "Copy liste of listes: liste.deepcopy()\n",
    "Remove value from liste: liste.remove(valueToRemove) \n",
    "Count nb of values in liste: liste.count()\n",
    "Display all methods available: liste.method()\n",
    "Unpack a liste: a,b,c = [1,2,3] #Will return ValueError if not enough variables to unpack \n",
    "Turn object into liste: list(object_To_Transform)\n",
    "Zip nested lists: list(zip(*nested_lists)) #where nested_lists = list of lists that you want to zip\n",
    "\n",
    "#Tuples\n",
    "#Tuples are immutable, but the variables contained are not necessarily of the same type. Can be accessed using index.\n",
    "#Ordered (print in the same way)\n",
    "#If your function returns  multiple variables,tuple is returned\n",
    "#Unpacking = access the multile results of a function as separate variables \n",
    "Unpack a tuple: return x1,x2 / rep1, rep2 = funct(x1,x2)\n",
    "Return a tuple: return (x1,x2) / return x1, x2\n",
    "\n",
    "\tBeware: \n",
    "\tAccess tuple value: since tuples are ordered, (tuple_name)[1] \n",
    "\tCas où tuple modifiable: you can access a list that is within a tuple. \n",
    "\t[Ex] tuple1 = ([liste], x) / you can write: tuple1[1].extend(liste2)\n",
    "\n",
    "#Sets\n",
    "#Sets are unorder, indicated by {set1,set2,...} - cannot use index, cannot be sliced, won't print in the same order\n",
    "#Each print is a visual representation of a set, not the set itself \n",
    "#Strict superset: at least has another element that does not exist in the subset \n",
    "Remove from set: x.remove(value_to-remove) #Removes value from the set. If doesn't exist, raises a KeyError. \n",
    "Discard from set: x.discard(value_to_remove) #Removes value from set. Does not raise a Key Error if value doesn't exist.\n",
    "Pop a random objet from a set: setName.pop() #If no elements to remove, raises a KeyError. \n",
    "Add smth to a set: setName.add() / setName.update(liste) #Since append/extend doesn't work, use add/update to extend\n",
    "Add a set to a set: existing_set.update(set_to_add)\n",
    "Update and keep intersection with another set: existing_set.intersection_update(set_to_compare)\n",
    "Update and remove elements found in another set: existing_set.difference_update(set_to_remove)\n",
    "Update and keep only new elements found in another set: existing_set.symmetric_difference_update()\n",
    "Apply set to other containers: set([liste]) \n",
    "Removing duplicates from list: set([liste])\n",
    "Intersection sets (A and B): set1.intersection(set2)\n",
    "Union sets (A or B): set1.union(set2)\n",
    "Difference sets (A-B): set1.difference(set2) #set 1 - set 2\n",
    "Is set empty: bool(set_to_text) returns False\n",
    "Symmetric difference sets: set1.symmetric_difference(set2) #not (A et B)\n",
    "\n",
    "\n",
    "\tWhen to use a set: to make data retrieval much faster through hashing \n",
    "\t\n",
    "\tHashing: given a set with no two identical values (would have the same hash) \n",
    "\tAnd all are immutable (otherwise, if the object were to change, its position in memory would no longer correspond with its hash)\n",
    "\t10 piles - Hash function = return int(x*100%31) | hash(pile) for pile in piles |\n",
    "\tfind the 5.37 box using int(5.37*100%31) #The 31 boxes is arbitrary \n",
    "\t#We find which of the 31 boxes the pile of money should be in \n",
    "\t#We calculate where in memory the data should be based on the value\n",
    "\tLists are unhashable; because lists might mutate and the hash wll be outdated . \n",
    "\tWe hash immutables: tuples, strings, numbers, booleans\n",
    "\n",
    "#Dicts\n",
    "#Curly brackets, made of several key/value pairs. Generally unordered.\n",
    "#Use hashing techniques on keys (/sets), cannot be accessed by index\n",
    "#Advantages: to label data and quickly retrieve it without pos: are referred to as lookup tables or hashtables \n",
    "#Dict of dicts: one tag = several values as output\n",
    "#In case you're going to use a complex algo several times, store results in dictionary to save computational time later\n",
    "#Beware: difficult to find stuff in the dictionary based on value\n",
    "Create a dictionary with zip: create key liste, value liste, zip them together \n",
    "#Note about zip: if argument sequences of unequal lengths, the return list is truncated to the length of the shorted arg sequence\n",
    "\n",
    "\tkey_list = ['name', 'age']\n",
    "\tvalue_list = ['Laetitia', '23']\n",
    "\tkey_value_pairs_liste = list(zip(key_list, value_list)) \n",
    "\t#Returns: [('name','Laetitia'), ('age', '23')]\n",
    "\tkey_value_pairs_dict = dict(zip(key_list,value_list))\n",
    "\n",
    "Unzip dict: scores, names = list(zip(*sn)) #Using the star makes the transpose\n",
    "Add new key-value pair with assignment: me_dict['favorite book'] = 'The little Prince'\n",
    "Add several new key-value pairs with update: me_dict.update({'fav color':'red', 'siblings':'2'})\n",
    "Reassign values in dict: me_dict['favorite book'] = 'The Lion King'\n",
    "Delete key and values: del me_dict['favorite book'] / me_dict.pop('siblings')\n",
    "Retrieve keys: me_dict.keys()\n",
    "Retrieve values: me_dict.values()\n",
    "Retrieve key-value pairs: me_dict.items()\n",
    "Retrieve values associated to keys: me_dict[2] returns values associated to key 2 \n",
    "Retrieve values associated to keys with get: print('has dog: %s' % me_dict.get('has dog'))\n",
    "Get with default value if key does not exist: me_dict.get('has cat', False)\n",
    "Iterate over keys: for key in me_dict(): \n",
    "\n",
    "\tBeware: \n",
    "\tKeys are immutable, you cannot use a list (unhashable type)\n",
    "\tSince tuple are immutable, you can use tuple to create keys.\n",
    "\tUse tuples when you want your key to contain multiple pieces of info. \n",
    "\tvalid_dict = {(1,5):'a',5:[23,6]}\n",
    "\tCan use list for values (one key = several values returned)\n",
    "\n",
    "# Switching dtypes, search, sorting, iteration and comprehension \n",
    "Map: map(func,seq) applies the func to all elements in a sequence #list(map(len,['Tina','Raj','Tom'])) returns [4,3,2] #Also works with custom functions\n",
    "Switching datastructure: tuple(ex_list)/ set(ex_tuple) / list(ex_set)\n",
    "Search in liste: print('a' in ex_list) returns True/False\n",
    "Search in dictionary: 'key_1' in me_dict returns True/False #we can search by key but not by value \n",
    "Search in dictionary values: 'brown' in me_dict.values() \n",
    "Sort tuples and sets with sorted: sorted(map(str, ex_tuple)) #Converts all elements into strings to sort easily \n",
    "Sort dictionary with sorted: sorted(me_dict.items()) / sorted(me_dict) #Returns sorted list of keys (or key-value pairs)\n",
    "Sort dictionary by values: sorted(map(lambda kv: (kv[0], str(kv[1])), me_dict.items()), key = lambda kv: kv[1]) #key goes with sorted /by value\n",
    "Iterating over dict items: unpack the keys and items first\n",
    "\n",
    "\tfor k,v in me_dict.items(): \n",
    "\t\tprint('%s : %s' % (k,v))\n",
    "\n",
    "List Comprehension: squares = [x**2 for x in range(10)]\n",
    "Dict Comprehension: {x: x**2 for x i range(10)}\n",
    "Print dict_values in different lines: list(dict_values()) / for el in list, print(el)\n",
    "Create new dictionary with Comprehension: \n",
    "\n",
    "\tme_dict_dtypes = {k: type(v) for k,v in me_dict.items()}\n",
    "\t# New dict keys = me_dict keys, values = dtype of each me_dict value\n",
    "\n",
    "#Collections library \n",
    "#Additional datastructures built on top of Python's: namedtuple, deque, Counter, OrderedDict, defaultdict\n",
    "#namedtuple: gives tags to elements of a tuple = combination tuple/dictionary. \n",
    "#Named tuples are a way to create self-documenting code with almost no memory cost\n",
    "Named tuples: \n",
    "\n",
    "\timport collections as clt\n",
    "\tVector = namedtuple('Vector',['x','y','z'], verbose = True) #Verbose shows class definition, Vector3 is a new object (3-dimensional vector), Vector is the name and x/y/z its attributes\n",
    "\tvec = Vector(1,2,3)\n",
    "\tvec returns Vector(x=1, y =2, z= 3)\n",
    "\tvec.x, vec.y, vec.z returns (1,2,3)\n",
    "\t#Useful since still immutable, values cannot be reassigned\n",
    "\n",
    "\t>>> from collections import namedtuple\n",
    "\t>>> Car = namedtuple('Car','Price Mileage Colour Class') #Car is a 4 dimension object/tuple? \n",
    "\t>>> xyz = Car(Price = 100000, Mileage = 30, Colour = 'Cyan', Class = 'Y')\n",
    "\t>>> print xyz\n",
    "\tCar(Price=100000, Mileage=30, Colour='Cyan', Class='Y')\n",
    "\t>>> print xyz.Class #Returns Y\n",
    "\n",
    "#Deques\n",
    "#Double-ended queue, treatable faster than big lists when dealing with first/alst elements\n",
    "#Below: same results but deque is much faster\n",
    "#Works with append, clear, extend, remove, reverse\n",
    "Append left: d.appendleft(number)\n",
    "Append right: d.appendright(number)\n",
    "Extend left: d.extendleft('234') # Add 2, 3, 4 as list\n",
    "Extend right: d.extend('234')\n",
    "Shift queue: d.rotate(3) #[1,2,3] becomes [3,1,2]\n",
    "\n",
    "\t\n",
    "\tfrom collections import deque \n",
    "\tl_ = list()\n",
    "\tfor i in range(40000): \n",
    "\t\tl_.insert(0,i) #insert i at pos 0 = list will start with 4000  \n",
    "\n",
    "\td = deque() \n",
    "\tfor i in range(40000):\n",
    "\t\td.appendleft(i)\n",
    "\n",
    "#Counters\n",
    "#Counts elements in an iterable and returns a dict structure containing the count \n",
    "Counter: \n",
    "\n",
    "\tfrom collections import Counter\n",
    "\tele = ['a','b','a','c','b','b','d']\n",
    "\tc = Counter(ele)\n",
    "\t#returns Counter({'b': 3, 'a': 2, 'c': 1, 'd': 1})\n",
    "\tc['a'] #returns nb of occurences of a. If a doesn't exist, will return 0.  \n",
    "\tc.most_common(2) #returns 2 most common elements + nb of occurences = [('b', 3), ('a', 2)] \n",
    "\n",
    "Create OrderedCounter: #Returns OrderedCounter(OrderedDict(...)) type of object. To interact, use habitual c.keys() or c.values()\n",
    "\n",
    "\tfrom collections import Counter, OrderedDict\n",
    "\tclass OrderedCounter(Counter, OrderedDict):\n",
    "     'Counter that remembers the order elements are first seen'\n",
    "     \tdef __repr__(self):\n",
    "        \t return '%s(%r)' % (self.__class__.__name__,\n",
    "                            OrderedDict(self))\n",
    "     \tdef __reduce__(self):\n",
    "        \t return self.__class__, (OrderedDict(self),)\n",
    "\n",
    "#DefaultDicts\n",
    "#set some default value that is returned when we want to access a key that doesn't exist \n",
    "#The default dict takes a default factory function e.g. return 0 whe the ke has not been seen before. \n",
    "#Works like a normal dict, but is initialized with a function ('default factory') that takes no arguments \n",
    "#And provides the default value for a non-existent key. A defaultdict will never raise a KeyError.\n",
    "#E.g ice_cream = defaultdict(lambda:'Vanilla') / price ice_cream['Joe'] will return Vanilla (if Joe doesn't exist)\n",
    "\n",
    "\tfrom collections import defaultdict\n",
    "\tdef count_default(x):\n",
    "    \tcount_dict = defaultdict(int)\n",
    "    \tfor ele in x:\n",
    "        \tcount_dict[ele] += 1 #For that key, if you have seen it before, add one in value of new dict \n",
    "    \treturn count_dict\n",
    "\tcount_default(ele)\n",
    "\n",
    "#OrderedDicts \n",
    "#Remembers the order with which each key was included in the dictionary:\n",
    "#If a new entry overwrites an existing entry, the original insertion position is left unchanged\n",
    "Create orderedDict: ordered_dictionary = OrderedDict() \n",
    "\n",
    "#Itertools\n",
    "Cartesian products: itertools.product(lists_or_tuples) / itertools.product(liste, repeat = nb) #Produit cartesien de la même liste/du même tuple\n",
    "Permutations iterable: itertools.permutations(iterable [,r]) #Returns successive rlength permutations of  elements in an iterable. \n",
    "#If r is not specified or is None, r defaults to length of the iterable \n",
    "#And all possible full length permutations are generated. Permutations are printed in a lexicographic sorted order\n",
    "#If the input iterable is sorted, the permutation tuples will be produced in a sorted order \n",
    "Combinations iterable: itertools.combinations(iterable[, r]) \n",
    "Combinations with replacements: itertools.combinations_with_replacement(iterable, r) #r-length tuples in sorted order, with repeated elements \n",
    "Filtering: iffilter(filter, seq) / iffilter(lambda x: x%2, range(10)) #returns 1 3 5 7 9 \n",
    "Filtering on opposite condition: iffilterfalse(filter,seq) #same as previous returns 0, 2, 4, 6, 8 \n",
    "Filter while: takewhile(filter, seq) / takewhile(lambda x: x<5, [1,4,6,4,3]) #returns 1 4 \n",
    "Slice string: islice(seq, start, stop[, step]) / islice('ABCDEFG',2,None) # returns C D E F G \n",
    "\n",
    "#Calendar functions\n",
    "#Calendar functions available here: https://docs.python.org/2/library/calendar.html#calendar.setfirstweekday\n",
    "Import calendar: import calendar \n",
    "Generate plain text calendars: calendar.TextCalendar(firstweekday=6) #0 is Monday, 6 is Sunday \n",
    "Set first week day: calendar.setfirstweekday(calendar.SUNDAY) #Could be MONDAY, TUESDAY, WEBDNESDAY\n",
    "Get current first wek day: calendar.firstweekday()\n",
    "Check if leap year: calendar.isleap(year)\n",
    "Get day: calendar.weekday(year, month, day) #retuns day of week - 0 is Monday for year (1970...), month(1-12), day(1-31)\n",
    "\n",
    "#Datetime \n",
    "#Datetime objects, also timedelta (useful since can be added, substracted, modulo, abs, str, rpr (string representation of timedelta object))\n",
    "#All class attributes of datetime: .min, .max, .resolution, .year, .month, .day, .hour, .minute, .second, .microsecond\n",
    "import datetime as dt \n",
    "Show current date: datetime.datetime.now().date()\n",
    "Show time delta: datetime.timedelta(_timeofyourchoice_) #Returns timedelta object (optional args: days = 0, seconds = 0, microseconds = 0, milliseconds = 0, minutes = 0, hours = 0, weeks = 0)\n",
    "Turn timedelta into seconds: timedelta.total_seconds() \n",
    "Show str representation of timedelta: repr(timedelta)\n",
    "Add timedelta to datetime object: date2 = date1 + timedelta \n",
    "Get timedelta between two dates = date2 - time1\n",
    "Assert differences between two dates: date2 < date 1 #returns bool \n",
    "Get nb of days in your timedelta: timedelta.days() / timedelta.seconds() / timedelta.microseconds()\n",
    "Show date as str: date.__str__() #Gets str representation (isoformat: YYYY-MM-DD)\n",
    "Show date as str with custom format: datetime_object.stfrtime(format) / date.__format__(format) #\"%d/ %m/%y\"\n",
    "Get timestamp: time.time() \n",
    "Convert timestamp to datetime: datetime.fromtimestamp(timestamp, tz = None)\n",
    "Combine date and time to create dt: datetime.combine(date, time, tzinfo = self.tzinfo)\n",
    "Turn string into datetime object based on custom format: dt.strptime(date_string, format)\n",
    "    \n",
    "\tdf['Date'] = pd.to_datetime(df['Date']) #we tranform to dates\n",
    "\tdf['Year'] = df['Date'].dt.year\n",
    "\tdf['Month'] = df['Date'].dt.strftime('%m') #Will show the month only as str\n",
    "\tdf['Monthday'] = df['Date'].dt.stdrtime('%d') #Will show the day only as str\n",
    "\tdf['Day'] = df['Date'].dt.Day \n",
    "\tdf['Debut Mois'] = df['Date'].dt.day(<0).fillna(0).astype('unit8')\n",
    "\tdf['Fin Mois'] = df['Date'].dt.days(>0).filna(0).astype('unit8')\n",
    "\n",
    "    \n",
    "#Dataframes\n",
    "#Cleansing the dset: drop the columns which do not add values, make the format uniform, create a column with time (prepare for time analysis)\n",
    "#Handle the missing values: when you have localized the columns which contribute the most to the analysis, remove nulls from them to avoid the inaccuracy of the predictions - ex with mean of columns\n",
    "#Finding questions you want to answer with your dset: \n",
    "#Which state has the highest CO2? Group values by state, the plot these values by mean over a year \n",
    "#What yearly trend in a particular state: follow max emission, find evolution of key historical values, plot \n",
    "#Beware with pandas: sometimes the csv rows will contain less data than index (some is missing). Should be indicated by ',,' on the csv file. \n",
    "#Upon import, pandas is unable to detect the case and just places a NaN at the end of the row (no matter where the NaN should have been placed)\n",
    "#Hence: lignes décallées: data values are assigned to the wrong cell\n",
    "#Hence: always inspect the dstructure (checking the NaNs) \n",
    "#How to fix the badly formatted CSV? File directly = add a ',' where it is missing (inefficient)\n",
    "Import from Excel: df = pd.read_excel('filepath')\n",
    "Print raw csv: !cat ./data/csv_name.csv\n",
    "Import from csv: df = pd.read_csv('filepath', index_col = 0)\n",
    "Write to to csv: pd.to_csv('filepath.csv')\n",
    "Create df from dictionary: \n",
    "\n",
    "\tfamily = {nomFam: [0,0], nompers: [0,0]}\n",
    "\tdf = pd.DataFrame(data = family)\n",
    "\n",
    "Export to Excel: df = pd.to_excel(nomPath)\n",
    "Get first and last rows: df.head(n) / df.tail(n)\n",
    "Get shape: df.shape() returns nb of rows, columns\n",
    "Display column names: df.columns() renvoie un array avec ts les noms de colonnes\n",
    "Quick stats: df.describe() / df.info()\n",
    "Display all row labels: df.index()\n",
    "Delete col: del df['NomCol'] \n",
    "Create new col: df['nomNouvelleCol'] = df['col1'] - df['col2']\n",
    "Dropper des colonnes: df = df.drop(df['ColToDrop'], axis=1) # Axis = 0 for a row\n",
    "Extract full name from path: ntpath.basename('filepath')\n",
    "Set index: df2 = df1.set_index('nomCOlonne', drop = False) # Si drop = True, l'ancien index va être supprimé \n",
    "Extract subset with names: df.loc[startRow:endRow, 'nomColonne'] / df.loc[:,'nomColonne'] / df[['nomCol1', 'nomCol2']]\n",
    "Apply mean to extract: df.loc[,:'nomCol'].mean()\n",
    "Extract a single cell with loc: df.loc['nomLigne','nomCol']\n",
    "Extract subset with position: df.iloc[:,0:4] #Wrn; fonctionne comme range, s'arrête en n-1\n",
    "Display df methods: dir(pd.DataFrame)\n",
    "Display method description: help(pd.DataFrame.mean)\n",
    "Add a column manually: df['nouvelleCol'] = [valeurRow1,valeurRow2,..]\n",
    "Add a column with mean in each row: df['nomNouvelleCol'] = df.mean(axis=1) #Axis = 1 pour nouvelle Col\n",
    "Add a column depending on logical test: df['nomNouvelleCol'] = df.apply(x series: 'Big' if series['col1']>series['col2' else 'Small'], axis=1)\n",
    "Display width: pd.display.options.width\n",
    "Display max nb of rows displayed: pd.display.options.max_rows\n",
    "Display max nb of columns displayed: pd.display.options.max_columns\n",
    "Column dtypes: df.dtypes\n",
    "Methods on aggregate: min(), max(), sum(), cumsum()\n",
    "Drop NA: df.dropna(axis=0)\n",
    "Fill NA: df.fillna(value_replacing_na) \n",
    "Replace NA with mean:df.fillna(mean(df.shift(-1),df.shift(+1))) / ffill / bfill\n",
    "Count nb nulls in df: df.isnull().sum()\n",
    "Transpose: df.T / df.transpose()\n",
    "Count nb nulls in rows: df.transpose.isnull().sum() #isnull fonctionne mieux par colonne\n",
    "Create categories / Label rows depending on cell value:  \n",
    "\n",
    "\tbins = [0,10,20,40]\n",
    "\tnames = [small, middle, big]\n",
    "\tdf['Column_bins'] = pd.cut(df.columns_names,bins,labels = names)\n",
    "\n",
    "Shape: df.shape #returns rows and columns\n",
    "Nb of null values in each column: df.isnull().sum() \n",
    "Nb of values: df.count()\n",
    "Select columns: df.columnName / df[['ColumnName']] / df.iloc[:,'columnNb']\n",
    "Replace NaNs: df.fillna(newValue)\n",
    "Select rows depending on logical test: df[df['Area'] == 'Ireland']\n",
    "Create indicator: df['Indicator'] = np.where(df['Colonne'] > df['Colonne2'], 'Col1>Col2', 'Condition pas vérifiée')\n",
    "\n",
    "\tAlternative:\n",
    "\tcondition1 = df['nationality'] == 'USA'\n",
    "\tcondition2 = df['age'] > 50\n",
    "\tdf[american & elderly] \n",
    "\n",
    "\tSelect the cases where the first name is not missing and nationality is USA\n",
    "\tdf[df['firstname'].notnull() & df['nationality'] == 'USA']\n",
    "\n",
    "\tRename columns df.rename(columns={'nouveauNom':'ancienNom', \n",
    "\t'Y001':'Year_2001'}, inplace = True)\n",
    "\n",
    "Rename all columns using a function: df.rename(columns =str.lower) / df.rename(columns =lambda x: x.lower().replace(' ','_'))\n",
    "Merge: merged = pd.merge(user_usage, user_device([['colName1','colName2']]), on='use_id', how='joinType') #joinType = left, right, inner, outer\n",
    "Factcheck the results: df1['ColID'].isin(df1['ColID']).value_counts()\n",
    "Merge indicator: optionality in merge, we can ask pd to add anothercolumn after the merge indicating from where each value comes \n",
    "Skew: df.skew([axis, skipna, level, numeric_only]) returns unbiased skew normalized by n-1\n",
    "Sort values df: df.sort_values(by, [axis, ascending, inplace, ...]) #df.sort_values(ascending = True) or df.sort_values(by = ['Name Columns'], axis = 0, ascending = False)\n",
    "Stdev: df.std([axis, skipna])\n",
    "Convert df to dictionnary: df.to_dict([orient,info])\n",
    "Convert df to csv: df.to_csv([path,sep,na_rep,...])\n",
    "Display subtotals each group: groupby('nomColGroup').agg({'nomCol1ToMean':'mean', 'nomCol2ToCount':'count'})  #Où dernière instruction = on compte, pr chaque groupe, cb d'occurences ds la colonne ID\n",
    "Pivot Table: pd.pivot_table(df, index=['ColumnName'], values =['colValues'], aggfunc = [np.mean])\n",
    "\n",
    "\tWarnings:\n",
    "\tnp.array().pop() removes an element by index\n",
    "\tnp.array();remove() removes an element by value\n",
    "\n",
    "\tThree methods to groupby:\n",
    "\tdf.groupby('day').agg({'VIX':'mean'})\n",
    "\tdf.groupby('day').VIX.mean()\n",
    "\tpd.pivot_table(df, index = ['day'], values=['VIX'], aggfunc = [np.mean])\n",
    "\n",
    "#Algorithms \n",
    "''' 3 majors bottlenecks in the code: \n",
    "- Computational complexity: how many instructions are executed? \n",
    "- Memory needs: how much memory is needed? \n",
    "- I/O: how many reads and writes or network requests do I need to make?\n",
    "The algorithm grows depending on the size of the problem. It's the algorithmic solution that has complexity. \n",
    "If we have N operations needed, we write O(N) to quantify complexity (order N). N measures the nb of inputs needed to compute the result. \n",
    "Note that only care about the dominant function of N in the expansion (hence O(N) = O(N+1) = O(2N))\n",
    "If we have nested for loops = O(N^how_many_loops)\n",
    "How to optimize storage? For instance, how to find a value in a list? Sorting itself = Nlog(N) complex\n",
    "ity, so the more optimized the better. \n",
    "- Basic approach: run through a list (if i == ele, return True)\n",
    "- Advanced1: early stop in sorted list: once you've exceeded the element you are looking for, exit the loop \n",
    "- Advanced2: binary search with recursive algorithm: allows the list to be divided roughly in half on each recursiv step, yielding a logarithmic asymptotic run time.\n",
    "Steps: look for midpoint element in list. If seeked < midpoint, then discard the upper part of the list. Then repeat. Nb of steps = log(N) in base 2.\n",
    "Memory complexity: if we have a list = O(N) - then list of list = O(N^2) etc\n",
    "'''\n",
    "\n",
    "Get random numbers: import random / random.randint(0, 10*N) \n",
    "Computing avg time: \n",
    "def compute(n_avgs, func, N): #Compute the avg\n",
    "    times = [] #Runs the function several time and stores the timing \n",
    "    for _ in range(n_avgs):\n",
    "        ts = time.time()\n",
    "        func(N)\n",
    "        times.append(time.time() - ts)\n",
    "    return sum(times)/float(len(times)) * 1000 # milliseconds\n",
    "\n",
    "Binary research script using recursive functions: \n",
    "def find_ele_binary(l_, ele): #l is our list, #ele the elment to find\n",
    "    if len(l_) < 1:\n",
    "        return False\n",
    "    mid_point = len(l_)//2\n",
    "    if l_[mid_point] == ele:\n",
    "        return True\n",
    "    elif l_[mid_point] > ele:\n",
    "        return find_ele_binary(l_[:mid_point], ele)\n",
    "    else:\n",
    "        return find_ele_binary(l_[mid_point+1:], ele)\n",
    "\n",
    "Memoization: to avoid repeating unnecessary steps or repeating calculation \n",
    "Steps: store results in dictionnary / inside the loop: check if result already stored / if not perform calculation \n",
    "Limits: we save computation but use more memory = its a tradeoff betwee the two\n",
    "\n",
    "\tfrom collections import defaultdict\n",
    "\tdef fibonacci_mem(n, d): #where d = defaultdict\n",
    "    \tif n in d:\n",
    "        \treturn d[n]\n",
    "    \telif n == 0:\n",
    "        \tans = 0\n",
    "    \telif n == 1:\n",
    "        \tans = 1\n",
    "    \telse:\n",
    "        \tans = fibonacci_mem(n-1, d) + fibonacci_mem(n-2, d)\n",
    "    \td[n] = ans\n",
    "    \treturn ans\n",
    "\tfibonacci_mem(33, {0:0,1:1})\n",
    "\n",
    "Factorial: math.factorial(n)\n",
    "Split string into letters: enumerate(string) #Returns enumerate object, to turn into list\n",
    "Use enumerate to find several minimums: \n",
    "\n",
    "\tdef locate_min(a):\n",
    "    \tsmallest = min(a)\n",
    "    \treturn smallest, [index for index, element in enumerate(a) \n",
    "                      if smallest == element] #Means that unpacks the enumerate and only return the index in index, element\n",
    "\n",
    "When there is more than one recursive call, use memoization to speed up the process \n",
    "If there is only one (factorial case): use memoization in a lookup table\n",
    "Insert while keeping list sorted with bisect module: \n",
    "\n",
    "\t#Python 3 program to insert an element into a sorted list\n",
    "\timport bisect \n",
    "\tdef insert(list, n): \n",
    "\t\tbisect.insort(list,n)\n",
    "\t\treturn list\n",
    "\n",
    "Choosing your data structure wisely:\n",
    "- Look at heaps (for binary search), depth (how to search in trees, networks), stacks, queus\n",
    "- Call stacks: certain algorithms are often linked to particular data structures = \n",
    "- The type of datastructure to use is often dependent on the algorithm we are going to implement. \n",
    "E.g. heap (heapq library) = tree-like structure useful for order statistics, such as keeping track of the largest/smallest N items in a ocllection. \n",
    "Even as you work through your miniprojects, choosing a dictionary instead of a list will make a difference between minutes/seconds of computation. \n",
    "\n",
    "#Object-oriented programming (OOB)\n",
    "#Why create a class: for making plots andgraphs, creating analyzing tables of data, doing statistics and regressions\n",
    "#When to define a new class: if we want to perform a set of related tasks, repeatedly\n",
    "#Most libraries introduce new classes to Python (e.g DataFrame in Pandas)\n",
    "\n",
    "- Object: anything with methods and attributes\n",
    "- Variable: object that lives in memory\n",
    "- Attributes: features of the state of a variable (e.g. being immutable). \n",
    "- Methods: attributes made of functions, capable of changing the state of the object (e.g. list.append())\n",
    "- We cannot reassign the attributes of an object easily (e.g. x.real = 5)\n",
    "- Class: blueprint for how objects should behave. Use majuscules.\n",
    "- Self: always first argument of the method __init__\n",
    "- Dunder methods: __init__ / __repr__ #Repr is called everytime you evaluate an object \n",
    "\n",
    "Find attributes and methods of an object: dir(object)\n",
    "Distinguish attributes from methods: object.method() / object.attribute #No brackets\n",
    "Find the class of an object: isinstance(object, expected_type)\n",
    "Find the class the object inherits from: isintance(object, expected_inherited_class) #type(s) == Square / isistance(s,Rectangle) both returns True\n",
    "Show documentation: x.to_bytes? #Bwr: remove method's brackets + ?\n",
    "Definition of a class: \n",
    "\n",
    "\tclass Rational(object): #Definition of a class: with majuscules (LinearRegression / linear_regression() for a function)\n",
    "\n",
    "    \tdef __init__(self, numerator, denominator): #Initialisation: creating the object\n",
    "        \tself.numerator = numerator #Create some attributes and initialize them\n",
    "        \tself.denominator = denominator\n",
    "\n",
    "    \tdef __repr__(self): #Representation: define how it is printed\n",
    "        \treturn '%d/%d' % (self.numerator, self.denominator)\n",
    "\n",
    "    #Just that is enough to print(Rational(4,3)) = 4/3\n",
    "    #If you get a __main__.Rational object at ... means thats you haven't defined __repr__\n",
    "    #You can still access the numerator and denominator, but no meaningful rpz of the object to print out \n",
    "    #Dunder methods not meant to be called directly from the main\n",
    "    #You can create supplementaty methods (besides init/repr). Note _additionalmethod(self) if not meant to be called directly (e.g. _gcd)\n",
    "    #Then you can call the supplementary method in another function: gcd = self._gcd()\n",
    "    \n",
    "\n",
    "Difference private/public methods: all methods in Python are public. But _additionalmethod() would be private and additionalNormalMethod() would be public\n",
    "Public methods: methods exposed to other jobjects or user interactin\n",
    "Private methods: used internally to the object, often in a helper sense \n",
    "Call an instance of a class: myclass = MyClass(2) and myclass.do_it() / MyClass.do_it(myclass) #in 2nd case, you need the argument \n",
    "The problem with new classes: if you want to do math with the result of your Rational, you need to specify the basic math relations in the dunder methods __add__, __div__, __mul__ etc.\n",
    "__add__ : programmer specified the operations following + #Note that even if it makes sense to you to overload it, it will be confusing to people reading the code + defining an 'add()' method is clearer \n",
    "\n",
    "\t#A class should handle all the ways the user could want to use an object\n",
    "\tDefining the methods of a class:\n",
    "\t\n",
    "\tclass Rational(object): \n",
    "\n",
    "\t\tdef reduce(self):\n",
    "        \tgcd = self._gcd()\n",
    "        \tself.numerator = self.numerator / gcd\n",
    "        \tself.denominator = self.denominator / gcd\n",
    "        \treturn self\n",
    "\n",
    "\t\tdef __mul__(self, number): #self = Rational, nb = the nb we're multiplicating against. Only works when Rational are on the left of the multiplication \n",
    "\t        if isinstance(number, int): #if the number is an int\n",
    "\t            return Rational(self.numerator * number, self.denominator)\n",
    "\t        elif isinstance(number, Rational): #if it is also a Rational\n",
    "\t            return Rational(self.numerator * number.numerator, self.denominator * number.denominator)\n",
    "\t        else: \n",
    "\t            raise TypeError('Expected number to be int or Rational. Got %s' % type(number))\n",
    "\n",
    "\t    def __rmul__(self, number): #To make sure that the multiplication works when Rational is on the right \n",
    "\t    \treturn self.__mul__(number)\n",
    "\n",
    "#Inheritance\n",
    "#Defining subclasses of objects with particular attributes/methods. E.g. square as a subclass of rectangle. \n",
    "\n",
    "\tclass Rectangle(object): #deifne class Rectangle \n",
    "    \tdef __init__(self, height, length):\n",
    "        \tself.height = height\n",
    "        \tself.length = length\n",
    "    \n",
    "    \tdef area(self):\n",
    "        \treturn self.height * self.length\n",
    "    \n",
    "    \tdef perimeter(self):\n",
    "        \treturn 2 * (self.height + self.length)\n",
    "\n",
    "    class Square(Rectangle): #SQUARE is a subclass of RECTANGLE\n",
    "    \tdef __init__(self, length): #Only one add argument since length = height\n",
    "        \tsuper(Square, self).__init__(length, length) #Overriding the Rectangle class with length = height # \n",
    "        \tRectangle.__init__(length, length) #Same way of writing the line above \n",
    "\n",
    "        def area(self): \n",
    "        \tprint('Calculating area of some square...')\n",
    "        \treturn super(Square, self).area()\n",
    "\n",
    "  \ts = Square(5) \n",
    "  \ts.area(), s.perimeter() #will return area and perimeter, without us having had to define the methods before\n",
    "\n",
    "#BASH commands \n",
    "#More on: https://medium.com/cameron-nokes/bash-commands-ive-found-most-useful-for-front-end-development-df66c8544c96\n",
    "Quick pick inside file: !cat filepath.extension\n",
    "Summary of file: !less server.log\n",
    "Open file with default app: open index.json \n",
    "Open file with custom app: open index.json -a TextEdit\n",
    "Open current directory: open . \n",
    "Create directory: mkdir my-folder\n",
    "Create subdirectory and parents: mkdir -p level1/level2/level3/level4 #Without the -p, mkdir will fail on non-existent directories\n",
    "Delete directory (all files, subs included): rm -rf level1 # -r for 'recursive', '-f' for force\n",
    "Create empty file: touch new_file.js / echo > myfile.js\n",
    "Create, initialize file: echo \"console.log('hello')\" > index.js\n",
    "Find with name: find . -name \"part_of_filename*.js\" #Accepts wildcards but not full regex\n",
    "Fihttps://www.programiz.com/python-programming/examples/conversion-binary-octal-hexadecimalnd, delete: find . -name \"*.log\" -delete\n",
    "Download file: wget http://.../.json.gz -nc -P ./pw-data #wget + full file path + receiving directory \n",
    "\n",
    "#Files\n",
    "#In scala: Dstructures immutables; functions declare what type of args they accept and the type they return \n",
    "#Readability comes first: simple > complex, flat > nested, sparse > complex \n",
    "#No multiple brackets as in Java, use minimalistic notations, one liners better than long text. Make it elegant.\n",
    "#Errors shouldn't pass silently! Error messages are a tool, so use the handlers. \n",
    "#In the face of ambuity, refuse the temptation to guess. Ambiguity whenever there is complexity. \n",
    "#Keep the code explicit with as many comments as necessary.\n",
    "#Explicitely silencing an error: with try:except. But precise the exception you want to catch. \n",
    "#Try/Except: aka 'ask for forgiveness, not permission'. Should remain exceptional.\n",
    "#Namespaces? \n",
    "#Flags: r/w/a/r+ (read + write)\n",
    "#We cannot open a file for reading if it doesn't already exist; but we can open it for writing (a new file)\n",
    "#Types of files: cvs (data splitted by comas), json, gzip, pickle \n",
    "Show file (fast): !cat ./filepath.extension \n",
    "Compare length of files: !ls -lh ./filename* #* to consider several formats of the same file\n",
    "Open file: f=open('./data/sample.txt','r') #Where f = file handler | 'r' = flag/mode, can be 'r' (read) or 'w' (write) or 'a' (append) = adds to the file, but doesn't override what was written before\n",
    "Read file: data = f.read() #File Handle = IO wrapper, with encoding etc\n",
    "Read one line: f.readline() / #using it twice will skip to the next line, as input() in HR\n",
    "Read all lines: f.readlines() #List of strings, each string = one line\n",
    "Write on file: f.write('text. \\n')\n",
    "Strip a line: line.strip() #Removes extra character in the file like \\n\n",
    "Close file: f.close()\n",
    "Context handler: #Only opens the file inside the with, then automatically close it at the end of the with \n",
    "\n",
    "\twith open('filepath', 'r') as f: \n",
    "\t\tprint(f.read())\n",
    "\n",
    "\twith open('filepath', 'w') as f: \n",
    "\t\tf.write\n",
    "\n",
    "Deleting one line from a file: #Stteps: open > read and get all lines > go write mode > write back all lines except the one you want to discard: \n",
    "\n",
    "\tLong version:\n",
    "\twith open(\"yourfile.txt\", \"r\") as f:\n",
    "    \tlines = f.readlines()\n",
    "\twith open(\"yourfile.txt\", \"w\") as f:\n",
    "    \tfor line in lines:\n",
    "        \tif line.strip(\"\\n\") != \"nickname_to_delete\": \n",
    "            \tf.write(line)\n",
    "\n",
    "    Single open with r+: \n",
    "    '''To consider: I wouldn't do this. If you get an error in the for loop\n",
    "    you'll end up with a partially overwritten file, with duplicate lines or a line half cut off. \n",
    "    You might want to f.truncate() right after f.seek(0) instead. \n",
    "    That way if you get an error you'll just end up with an incomplete file. \n",
    "    But the real solution (if you have the disk space) is to output to a temporary file and then use os.replace() \n",
    "    or pathlib.Path(temp_filename).replace(original_filename) to swap it with the original after everything has succeeded.'''\n",
    "    with open(\"target.txt\", \"r+\") as f:\n",
    "    \td = f.readlines()\n",
    "    \tf.seek(0)\n",
    "    \tfor i in d:\n",
    "        \tif i != \"line you want to remove...\":\n",
    "            \tf.write(i)\n",
    "    \tf.truncate()\n",
    "\n",
    "Package to navigate file system: os \n",
    "Browse through directory: import os / os.listdir('.') # '.' for curr directory, dirpath otherwise\n",
    "Browse through subdirectory: os.listdir('./name_of_sub') #Subs obv do not have file extensions\n",
    "Browse through the location + all subs: os.walk(top, topdown = True, onerror= None,...)\n",
    "Set where to seek files: os.chdir('/home/user/directory_to_look_at')\n",
    "Create directory: os.makedirs(name, mode=?, exist_ok = False)\n",
    "Show paths to files using walk: \n",
    "\t\n",
    "\tShow everything\n",
    "\tfor root, dirs, files in os.walk('.'):  # ~ or /home/user/directory. Os.walk generates a 3-tuple (dirpath, dirnames, filenames)\n",
    "    \tfor file in files: \n",
    "        \tprint(os.path.join(root, file))\n",
    "\n",
    "\tShow paths for csv only\n",
    "\tshwfiles = []\n",
    "\tfor dirpath, subdirs, files in os.walk(path):\n",
    "    \tshwfiles.extend(os.path.join(dirpath, x) for x in files if x.endswith(\".csv\"))\n",
    "\n",
    "Parsing without Pandas: #Could use namedtuples also\n",
    "\n",
    "\tlist_tables = []\n",
    "\twith open('./data/csv_sample.txt','r') as f: \n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\trow = lne.strip().split(',')\n",
    "\t\t\tlist_table.append((int(row[0]), row[1], int(row[2]))\n",
    "\tlist_table returns liste of listes (each represents a row)\n",
    "\n",
    "Downloading file if not in directory: \n",
    "\n",
    "\tif 'factbook.csv' not in os.listdir('./data/'): #Replace by os.walk('./data/') to explore all the subs\n",
    "    \t!wget -P ./data/ https://perso.telecom-paristech.fr/eagan/class/igr204/data/factbook.csv\n",
    "\tcountries = pd.read_csv('./data/factbook.csv', delimiter=';', skiprows=[1])\n",
    "\n",
    "\t%% bash \n",
    "\tmkdir pw-data\n",
    "\twget http://dataincubator-wqu.s3.amazonaws.com/pwdata/practices.json.gz -nc -P ./pw-data\n",
    "\n",
    "Get filename: f.name\n",
    "Tell current position of pointer in the file: f.tell()  #in bytes\n",
    "Use seek to change pointer position: f.seek(offset, whence) #Where offset is the nb of characters, whence = pos where starts reading (os.SEEK_CUR for current pos, os.SEEK_SET for beginning, os.SEEK_END to go at the end of the file). Note: moving the cursor = f.read() will display the remaining line\n",
    "Find row: print('found at line %s' % [num for num, line in enumerate(f, 1) if 'data' in line])\n",
    "\n",
    "\tlookup = 'the dog barked'\n",
    "\twith open('filepath', 'r+') a f: \n",
    "\t\tfor num, line in enumerate(f, 1): \n",
    "\t\t\tif lookup in line: \n",
    "\t\t\t\tprint('found at line', num)\n",
    "\n",
    "#JSON\n",
    "#Data received from API (twitter, google...) will be JSON (JavaScript Object Notations) \n",
    "#Data structure made of nested dictionaries and lists \n",
    "#Advantage: doesn't have to conform to tabular structure, can be shared quickly over the internet (hence must be kept small = no redundancy of data)\n",
    "#Problem: typical json file structure is tedious to write - typically requires to loop through dictionaries or write repeatedly the tags\n",
    "#JSON subtypes, regular JSON, new JSON, simple JSON \n",
    "#JSON files are just text files. If we just read them = will only appear as one string. \n",
    "#Warning: writing json files based on Python entries will turn tuples into lists, cannot represent a dummy class...\n",
    "Import JSON library: import json \n",
    "\n",
    "\tTypical JSON: \n",
    "\tbook1 = {'title': 'The Prophet',\n",
    "         'author': 'Khalil Gibran',\n",
    "         'genre': 'poetry',\n",
    "         'tags': ['religion', 'spirituality', 'philosophy', 'Lebanon', 'Arabic', 'Middle East'],\n",
    "         'book_id': '811.19',\n",
    "         'copies': [{'edition_year': 1996,\n",
    "                     'checkouts': 486,\n",
    "                     'borrowed': False},\n",
    "                    {'edition_year': 1996,\n",
    "                     'checkouts': 443,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "         \n",
    "\tbook2 = {'title': 'The Little Prince',\n",
    "         'author': 'Antoine de Saint-Exupery',\n",
    "         'genre': 'children',\n",
    "         'tags': ['fantasy', 'France', 'philosophy', 'illustrated', 'fable'],\n",
    "         'id': '843.912',\n",
    "         'copies': [{'edition_year': 1983,\n",
    "                     'checkouts': 634,\n",
    "                     'borrowed': True,\n",
    "                     'due_date': '2017/02/02'},\n",
    "                    {'edition_year': 2015,\n",
    "                     'checkouts': 41,\n",
    "                     'borrowed': False}]\n",
    "         }\n",
    "\n",
    "Create JSON from python dstructure: import json / with open('./file.json', 'w') as f: / json.dump(library, f, indent = 2) #Then !cat ./file.json to show the properly formatted json \n",
    "Load JSON into dstructures: import json / with open('./file.json', 'r') as f: / reloaded_library = json.load(f) \n",
    "Parse JSON string: json.loads(f.read()) #will only work with f.read()#Will return a list instead of a string (f.read())\n",
    "Pandas read JSON: pd.read_json('./file.json') #Will try reading the json into a table - but will show hierarchies in cells (not useful)\n",
    "Pandas read JSON from API/Internet: pd.read_json('https://api.github.com/repos/.../issues?per_page=2')\n",
    "\n",
    "#Gzip\n",
    "#Compressed files use .zip or .gz (use deflate algo?)\n",
    "#Idea: look for repeated patterns in the file and points to the last appearance of a pattern and length of the match with that pattern\n",
    "#Compressed files are binary: hence 'wb' as a flat (write binary)\n",
    "#Won't compress well on random data or small files\n",
    "#On binary files, the !cat method will only show filename + some other stuff = cannot read \n",
    "Import gzip library: import gzip\n",
    "Open gzip: with gzip.open('./file.gz', 'wb') as f: / f.write(text.encode('utf-8')) #Encode if non ASCII characters - nothing to do with gzip\n",
    "\n",
    "#Pickle\n",
    "#Pickle is an example of serialization = often, we work with complex objects stored in memory; but we may need to move these objects to another computer\n",
    "#Or write them persistently in memory so that we can shut down the interpreter and work with them again another time\n",
    "#Ex: ML model that we spent a long time training = serialize it to disk to send it to a network or reuse it another time to make predictions\n",
    "#Json & csv can be used to write smth in text on disk. What about more complex formats? (ML models...)\n",
    "#You can pickle a dummy class\n",
    "Import pickle library: import pickle\n",
    "Create pickle: with open('./filename.pkl', 'wb') as f: / pickle.dump(pickle_example, f)\n",
    "Load pickle: with ... as f: / loaded_ex = pickle.load(f)\n",
    "Pandas read pickle: pd.read_pickles(data = '')\n",
    "Pandas export to pickle: pd.to_pickle('filepath.pkl')\n",
    "Pickle a dummy class: \n",
    "\n",
    "\twith open('./dummy_class.pkl', 'wb') as f: \n",
    "\t\tpickle.dump(DummyClass, f)\n",
    "\n",
    "#NumPy - file formats (.npy)\n",
    "#Along with SciPy = part of the older Python packages. Both were the tools that made \n",
    "# Python an attractive programming language. What does it offer: \n",
    "''' \n",
    "- Mathematical functions: sin, log, floor, ceiling, exponential... \n",
    "-  Random Submodule (useful for random sampling)\n",
    "-  NumPy ndarray = n dimensional array. Similar to a n-dimensional matrix or tensor. Works like a list of list, \n",
    "where the depth of the inner list makes up for the array dimension. Each list is a row in this array. \n",
    "Not limited to 2 dimensional (matrix), 3 (cube - then you have row/columns/depth...) \n",
    "Such arrays are often used for representing images, in which case they are two-dimensional. \n",
    "Note that a numpy array has a shape =/= list of lists, where each inner list has a different length. \n",
    "Everytime we have an array with different dtypes inside, then i'll  consider the dtype as object.\n",
    "If dtype('<U5') just means that the memory allocated is smaller than that. \n",
    "Inside an array: at best, boolean/int/floats. Outside of that, choose another dstructure.\n",
    "#Summing the numbers in an array is much easier than for a list of lists. \n",
    "#Why is it better than lists of lists: when a list is summed, Python needs to figure out the correct way to add \n",
    "#the elements of the list together v when ndarray is summed, NumPy already knows the type of each element (and they are consistent)\n",
    "#this, can sum without checking the correct add function for each element \n",
    "#List stuff: every time Python is adding up nb, it wonders what addition means. Can add 6 + True considering True = 1. \n",
    "#NumPy is 10x faster + has a much better syntax for performing computations on collections of numbers\n",
    "#NumPy is the basis for many other datascience packages\n",
    "'''\n",
    "Import numpy: import numpy as np \n",
    "Turning a list of lists into a numpy array: array1 = np.array(list_of_lists) #If the inner lists are of different length, then it'll consider each row = 1 list; and make it a one dimensional object. \n",
    "Numpy export array to text: np.savetext('filepath.txt', sample_array)\n",
    "Sum number inside array: an_array.sum()\n",
    "Sum of nb inside array rows: an_array.sum(axis = 1)\n",
    "Sum of nb inside array columns: an_array.sum(axis=0)\n",
    "Add scalar to array: an_array + 5 #returns each value in the array + 5 \n",
    "Multiply array by scalar: array*5\n",
    "Divide array by scalar: array/5\n",
    "Add two arrays: array1 + array2 \n",
    "Sum inside array: np.sum(my_array, axis = 0/1/None) #If None, returns sum of all values\n",
    "Prod inside array: np.prod(my_array, axis = 0/1/None)\n",
    "Transpose array: np.transpose(array) \n",
    "Correlation coefficient: np.corrcoef(x,y) #où x et y sont un array \n",
    "Reshape array: Ar.shape() gives you the shape, ar.reshape(nb rows, nb cols) reshapes the ar\n",
    "Inner/outer matrix product: np.inner(A,B) / np.outer(A,B)\n",
    "Add arrays: np.add(a,b)\n",
    "Substract arrays: np.substract(a,b)\n",
    "Multiply arrays: np.multiply(a,b)\n",
    "Divide arrays to float: np.divide(a,b)\n",
    "Divide arrays to int: a%b / np.mod(a,b)\n",
    "Power arrays: a**b / np.power(a,b) #returns a^b\n",
    "Find coef polynomial given the roots: np.poly([list of roots]) \n",
    "Find roots polynomial given the coefficients: np.roots([list coefs])\n",
    "Find antiderivative (indefinite integral) of a polynomial: np.polyint([list coefs])\n",
    "Find derivative of a specified order of a polynomial: np.polyder([list coefs], m= k) #where k = order of differentiation\n",
    "Evaluate polynomial at specific value: np.polyval([coefs], value) \n",
    "Find polynomial of specified order fitting set of data (LS approach): np.polyfit([list data1], [list data2], order) #returns coefs\n",
    "#See polyadd, polysub, polymul, polydiv to handle basic arithmetic for polynomials\n",
    "Cross product of two arrays: np.cross(arr1, arr2) #returns prod diag - prod opposite diag \n",
    "Turn array into flat line: array.flatten()\n",
    "Mean of array rows: np.mean(array, axis =0) #compute mean for each row\n",
    "Mean of array: np.mean(array) / np.mean(array, axis = None) #Works the same with np.var() and np.std()\n",
    "Multiply two arrays (element wise): array1 * array2\n",
    "Divide two arrays (element wise): a/b.astype(float) #Note that the dividing array or scalar must be a float \n",
    "Dot product of two arrays: np.dot(a,b) #inner product - multiply all possible pairs, create a n*n matrix as the output (from a 1*5 * 1*5) \n",
    "Outer product of two arrays: np.outer(a,b)\n",
    "Numpy export array to npy: np.save('filepath.npy', sample_array)\n",
    "Numpy load array: np.load('filepath.npy')\n",
    "Get array shape: an_array.shape \n",
    "Get array dtype: an_array.dtype #np arrays have homoegeneous dtypes:each element could be an integer with 64 bits of memory attached (int64) \n",
    "Create 1dim array with start, end, nb of dpoints equidistant: np.linspace(0,10,5) #creates 5 dots between 0 and 5 separated by same distance #BEWARE: LINSPACE KEEPS THE UPPER BOUND\n",
    "Create 1dim array with start, end, stepsize: np.arange(1,10,1)\n",
    "Create 1dim array with logarithmic-spaced points: np.logspace(1,10,10) #Goes from 1^10 to 10^10. By default, base is 10. \n",
    "Create 1dim array with zeros: np.zeros(10) #default type is float, can change using np.zeros((nb rows,nb cols, depth), dtype = np.int)\n",
    "Create 3dim array with zeros: np.zeros(depth, height, length) # 2,10,5 will return two similar matrix 10 rows * 5 columns\n",
    "Create diagonal array: np.diag([1,2,3,4]) returns a 4*4 matrix with the list in diagonal\n",
    "Create identity matrix: np.identity(5) returns 5*5 matrix with ones in diagonal\n",
    "Create diagonal matrix with ones: np.eye(nb rows, nb cols, k) #k > 0 = positive diagonal, k< 1 = negative, k= 0 if main diag (identity)\n",
    "Change type of nb inside array: array.astype(int) #verify with array.astype(...).dtype\n",
    "#Note that you can convert booleans into floats doing; np.array([True, False]).astype(float) #false = 0 | true = 1\n",
    "Universal functions: NumPy defines a ufunc that allows to run functions over array. Many of these functions, like np.cos are built in and compiled with C code. \n",
    "# The function peform broadcasting, which allows them to automatically handle operations between arrays of different shapes (for ex 2 arrays wth the same shape, or one array + one scalar)\n",
    "Select part of array: array[row_nb_start:row_nb_end, column_nb_start:column_nb_end]  #select from first column to ante-last = 0:-1\n",
    "Apply mean to array: array[:,:].mean()\n",
    "Get max in array: array.max(axis = 0/1)\n",
    "Get floor in array (element-wise): np.floor(my_array) #Returns floats\n",
    "Get ceiling in array (element-wise): np.ceil(my_array) #returns floats\n",
    "Round to nearest integer in array (element-wise): np.rint(my_array)\n",
    "Round to a certain decimal place: np.around(a, decimals = 0, out = None)\n",
    "Find index at which max occured: array.argmax() #Add 1 to get actual nb, since count starts at python\n",
    "Turn array into list: array.ravel().tolist() #Returns one big column with all the values in order\n",
    "Slice array according to condition: random_array[random_array % 2 == 0] returns an array with only even elements\n",
    "Conditional filtering: random_array % 2 == 0 #Returns array of the same size as original, with only boolean (True or False depending on the condition)\n",
    "Extract elements from array according to index: array[[index1,index2,index3,index4]\n",
    "Extract value from array according to matrix pos: array[1,1] #returns value at pos 1,1\n",
    "Reshape array; array.reshape(new_nb_lignes, new_nb_columns) #Valid as long as the new matrix contains the same nb of values\n",
    "#You could change shape by modifying the attributes directly \n",
    "Horizontal Stack: np.hstack(a,b) #turns everything in a line - concatenate\n",
    "Vertical stack: np.vstack(a,b) # one row below another\n",
    "Depth stack: np.dstack(a,b) \n",
    "Turn array into 1D array (list): matrix.ravel()\n",
    "Transpose the array: matrix.transpose() #Also valid for non square matrices\n",
    "\n",
    "    Stack: \n",
    "\ta = np.array((1,2,3))\n",
    "\tb = np.array((2,3,4))\n",
    "\tnp.column_stack((a,b))\n",
    "\tarray([[1,2],\n",
    "\t\t   [2,3],\n",
    "\t       [3,4]])\n",
    "                                                                                              \n",
    "\tFind week periodicity with arrays: #Array representing one month = 4*7 (7 days, 4 weeks) = 7 columns, 4 rows\n",
    "\tfrom fractions import Fraction\n",
    "\tnormalized_sales = (jan_coffee_sales - jan_coffee_sales.mean()) / abs(jan_coffee_sales - jan_coffee_sales.mean()).max()\n",
    "\tfrequencies = [Fraction.from_float(f).limit_denominator() for f in np.fft.fftfreq(normalized_sales.size)]\n",
    "\tpower = np.abs(np.fft.fft(normalized_sales.ravel()))**2\n",
    "\tlist(zip(frequencies, power))[:len(power) // 2]\n",
    "\n",
    "\t#Returns frequencies \n",
    "\t#Like Fraction(1,28) = once every 28 days...\n",
    "\tWeekly rythm = Fraction(1,7) and the number on the right points at the power of the signal for that frequency     \n",
    "                                                      \n",
    "#Linear Algebra submodule: linalg \n",
    "#Check documentation: much more available!\n",
    "Get determinant of array: np.linalg.det(my_array)\n",
    "Find eigenvalues and eigenvectors of square array: values, vectors = np.linalg.eig(my_array)\n",
    "Inverse of matrix: np.linalg.inv(my_array)\n",
    "\n",
    "#Random Submodule\n",
    "Random values in given shame: rand(d0, ..., dn)\n",
    "Sample from std normal distrib: randn(d0,...,dn)\n",
    "Random integer: randint(low, high, size = (nb rows, nb columns))\n",
    "Radom floats in [0,1[ : random_sample(size)\n",
    "Random sample chosen in 1D array: choice(array, [size])\n",
    "\n",
    "#Visualizing Data with Matplotlib  \n",
    "#plt.plot(smth) will draw over the same graph, if repeated, as long as the .plot are included in the same notebook cell \n",
    "#plt is a state machine: all mods you make depend on the current state of plt\n",
    "#If plt is closed, calling plt gets you a new figure for your times series\n",
    "#Not necessarily clear from the code itself to figure what's going to happen.\n",
    "#Hence, name your figures instead = object-centered model. \n",
    "#Note that writing to create plots is a task customized to the data you are working on - don't spend time creating functions. \n",
    "#Also, don't spend too much time working on plottig libraries: instead, draw a picture of the graph you'd like to make (based on the dset you have)\n",
    "#And then, go dig into seaborn/matplotlib docs = they have galleries of pictures of what people have made, and code is available. \n",
    "#Hence: copy the relevant code and adapt it. \n",
    "Matplotlib, Pandas  Visualisation, Seaborn, Ggsplot, Plotly \n",
    "Multiple figures: plt.figure() / plt.plot(smth) / plt.figure() / plt.plot(smth_else)\n",
    "Importer: import Matplotlib.pyplot as plt \n",
    "\n",
    "\tStock price function (with arg = nb of days and initial price)\n",
    "\t\t\n",
    "\t\tdef gen_stock_price(days, initial_price):\n",
    "\t    \t# stock price grows or shrinks linearly\n",
    "\t    \t# not exceeding 10% per year (heuristic)\n",
    "\t    \ttrend = initial_price * (np.arange(days) * .1 / 365 * np.random.rand() * np.random.choice([1, -1]) + 1)\n",
    "\t    \t# noise will be about 2%\n",
    "\t    \tnoise = .02 * np.random.randn(len(trend)) * trend #using random from normal distrib\n",
    "\t    \treturn trend + noise\n",
    "\n",
    "\t    days = 365\n",
    "\t\tinitial_prices = [80, 70, 65]\n",
    "\t\tfor price in initial_prices:\n",
    "\t    \tplt.plot(np.arange(-days, 0), gen_stock_price(days, price))\n",
    "\t\t\tplt.title('Stock price history for last %d days' % days)\n",
    "\t\t\tplt.xlabel('Time (days)')\n",
    "\t\t\tplt.ylabel('Price (USD)')\n",
    "\t\t\tlt.legend(['Company A', 'Company B', 'Company C'])\n",
    "\n",
    "\n",
    "Name a figure: fig = plt.figure(figsize =(length,height))\n",
    "Add gen title to subplots: fig.suptitle('Suptitle')\n",
    "Create histogram: ax1.hist(data)\n",
    "Create scatterplot: ax1.scatter(data_axis_x,data_axis_y, label='Title')\n",
    "Set labels for scatterplot axes: ax1.set_xlabel('name of label1') / ax1.set_ylabel('name of label 2')\t\n",
    "Show legend: plt.legend()\n",
    "Customize plot line: plt.plot(N_range, time_sum, 'o-', label='Sum Numbers')\n",
    "\n",
    "\tCreate subplots: \n",
    "\tax1 = plt.subplot(221) #2x2 squares, pos = 1 starting from top left corner. \n",
    "\tax1.hist(shoes)\n",
    "\tax1.set_xlabel('Shoe size')\n",
    "\tax1.set_ylabel('Counts')\n",
    "\n",
    "\tScatterplot several features\n",
    "\tcolors = {'Iris':'r', 'Violet':'g','Other': 'b'} #Create a dictionary associating a dot color with afeature\n",
    "\tfig, ax = plt.subplots()\n",
    "\tfor i in range(len(iris['sepal_length'])):\n",
    "\t\tax.scatter(iris['sepal_lengthh'][i], iris['sepal_width'][i], color = colors[iris['class'][i]])\n",
    "\t#then set labels and columns \t\n",
    "\n",
    "\t#Show reg line on your scatterplot\n",
    "\tfit_line = linregress(shoes, jerseys)\n",
    "\tax3.plot(shoes, fit_line[1] + fit_line[0] * shoes, 'r', label='Line of best fit')\n",
    "\n",
    "\n",
    "#Pandas \n",
    "#Much more powerful than Excel! \n",
    "#PDs gets us to name the fields or entities of our data structure = no need for remembering the index or positioning. \n",
    "#Each column repreents a different type of data = aka \"field\"\n",
    "#Each row is named \"record\" or \"entity\"\n",
    "#How to create dfs besides importing the data: use zip, excel, csv, json?\n",
    "#Panda series: a single column of data, with a name (field name) and an index (number  if index not set, or string/tuple/boolean... if index set)\n",
    "#A df is essentially a dictionary of data series = access fields using df['name of field']\n",
    "#Trying to retrieve an unexisting series will hence return a KeyError\n",
    "#Since all series are built using np arrays, each series is expected to have a homogeneous dtype (object, bool, int, float mostly)\n",
    "Describe df: df.describe()\n",
    "Find index: df['series_name'].index\n",
    "Access a cell based on name and pos: df['series_name'][100] = '...' #where 100 = row pos\n",
    "Creating df and set index: df = pd.DataFrame({'shoe_size': shoes, 'jersey_size': jerseys}, index = players)\n",
    "Apply numpy functions to df: np.log(df) #Only if df fields of appropriate dtype\n",
    "Show field means: df.mean()\n",
    "Show entity values with index: df.loc['Ronaldo']\n",
    "Show multiple fields: df.loc[[field1,field2],:]\n",
    "Show multiple continuous fields: df.loc['Ronaldo':'Best', :]\n",
    "Position-based indexing; df.iloc[:,:]\n",
    "Add a new row with index: df.loc['Dylan'] = {'jersey_size': 91, 'shoe_size': 9, 'position': 'midfield'} #note the brackets\n",
    "Add a new column: df['position'] = np.random.choice(['goaltender', 'defense', 'midfield', 'attack'], size=len(df)) #Where each row value is chosen randomly among the list \n",
    "Build df from dict: df = pd.DataFrame({'name_field_1': list1, 'name_field_2':list2}) #Makes sense: built the columns as lists, then assemble them together\n",
    "\n",
    "\tBuild df from np array: \n",
    "\t# 1/ Generate a np array using rand \n",
    "\t# 2/ Name the rows, then the index \n",
    "\trandom_data = np.random.random(4,3) #matrix 4 rows, 3 columns\n",
    "\tdf_random = pd.DataFrame(random_data,columns=['a','b','c'], index=['row1','row2','row3','row4'])\n",
    "\n",
    "#WORK WITH INDEXES - bc it's easier to locate data & if indexes bt df match, you can merge them\n",
    "Drop row: df.drop(row_number) #drop(4) would work for the 5thr row + omitting inplace = True creates a copy of the original df \n",
    "Set index: df.set_index('name of field', inplace=True) #could have been done upon index creation\n",
    "Reset index to be an enumeration of rows: df.reset_index(inplace=True)\n",
    "Set index name: df.index.name = 'name of index' \n",
    "Set multiple indexes: df.set_index(['name field 1', 'name field 2'])\n",
    "Add df with same index: df_a + df_b\n",
    "\n",
    "#Reading data from file \n",
    "#Pd can read from Json, HTML, csv, Excel, Python, pickle or even use a database connection \n",
    "#There are plenty of options for pd.read_csv(), check documentation 'IO Tools'  \n",
    "#Excel: you can handle retrocompatibility as well\n",
    "Display pandas version: pd.__version__ \n",
    "Read csv and set index: pd.read_csv('filepath',index_col = pos_col) #specify a nb as pos_col\n",
    "Read csv without header and add field names: pd.read_csv('filepath', names = ['...'], header=None)\n",
    "Read csv and specify delimiters: pd.read_csv('filepath', delimiter= '\\t')\n",
    "Include datetime of row data in csv df: pd.read_csv('filepath', parse_dates = ['dates of creation']) #the new column will be of datetime dtype\n",
    "\n",
    "\tLoading json into df: #Long \n",
    "\timport gzip\n",
    "\timport simplejson as json\n",
    "\twith gzip.open('./data/yelp.json.gz', 'r') as f: #decompress the file\n",
    "\t    yelp_data = [json.loads(line) for line in f] #parse the file into a json dstructure\n",
    "\tyelp_df = pd.DataFrame(yelp_data)  #turn into df \n",
    "\tyelp_df.head() #Note that the table contains dstructures (dictionaries or list) = unusual but still works well in our case (the data isn't \"flat\")    \n",
    "\n",
    "\tLoading json into df: #Short\n",
    "\t#Note that the json may be stored in a file as a long string or multiple lines in the file\n",
    "\t#Hence in the read_json options, 'lines' arg (boolean) can be set to True (default: False)\n",
    "\t#Most important keyword = 'orient': tell pandas if the json is a list of dictionaries (orient: records), less common = split (see doc)\n",
    "\t#Hence: 1/ Check format of your json using: !zcat filepath.gz | head\n",
    "\t#If records:many dictionaries, within which each key is a column name.\n",
    "\t# 2/ set orient \n",
    "\t# 3/ Specify if compressed\n",
    "\tdf = pd.read_json('filepath', orient= 'records', compression = 'gzip')\n",
    "\n",
    "\tUnzipping gzip csv into pd: \n",
    "\tdf = pd.read_csd('filepath.csv.gz', compression = 'gzip')\n",
    "\n",
    "\n",
    "#Filtering \n",
    "#Note that the filter can come from another df, as long as the two dfs share the same index or they share a column\n",
    "#Logical operators: ~ = Not, | = Or, & = And\n",
    "#Contains is useful when names are not properly formatted\n",
    "Filter df based on conditions: df[(df['state'] == 'Arizona') and (df['review count'] >10)] #writing df['state'] == 'AZ' returns series of booleans (True or False for each row)\n",
    "Count how many results are filtered: df[df['state'] == 'Arizona'].count() / df['city'].nunique() #nb of distinct entities\n",
    "Use negation to filter: df[~df['open']] #returns all the businesses that are closed\n",
    "Verify df filter: df['state'].unique() #Returns an array of the same dtype, showing the condition you filtered on \n",
    "Filter on contain string: pd.Series([....]).str.contains('word you want') or df[df['city'].str.contains('Vegas')] #first option returns a series of booleans\n",
    "\n",
    "#Apply \n",
    "#Note that transforming the data using stat functions only works with relevant dtypes. If one cell contains a dict or a list, much harder to deal with.\n",
    "Apply log: new_col = np.log(df['columns to log'])\n",
    "Apply mean: mean_of_col = df['review_count'].mean()\n",
    "Show all means: df.mean() #will only return means for relevant dtypes (float, int)\n",
    "Show column names: df.columns\n",
    "\n",
    "\tInteract with cells containing a dict:  \n",
    "\tdef get_delivery_attr(attr_dict): \n",
    "\t\treturn attr_dict.get('delivery') #returns true or false depending on the value of delivery for each dict in the attr column\n",
    "\t\n",
    "\t# For one shot check, use: get_delivery_attr(df.loc[0,'attributes']) #interact with first dict \n",
    "\tdelivery_attrib = df['attributes'].apply(get_delivery_attr) #Apply that function to each row. Note that we don't call the function = no parenthesis, no args\n",
    "\n",
    "Fill NA with False: df['delivery'].fillna(False).head() #not a mutation since we don't use inplace = True\n",
    "Find all restaurants with delivery: df[df['categories'].apply(is_restaurant)]['delivery'].fillna(False).mean() #fill NA is not optional \n",
    "Use lambda functions (to use a function once, then erase it): df[df['categories'].apply(lambda x: 'Restaurants' in categories)]['delivery'].fillna(False).mean() #lambda replaces def to use a function in a one shot\n",
    "\n",
    "#Aggregate with groupby\n",
    "#Aggregation = overloaded term, might refer to summarizing data (ex: computing mean) or actually aggregatin gdata \n",
    "#Pattern of work: split - apply - combine => See documentation on pandas\n",
    "#Splitting: th data into some groups\n",
    "#Apply: some function to each group = represent each group by a subset or some statistics\n",
    "#Combine the results into a final datastructure\n",
    "#Whenever we group by smth, the distinct entities we chose to group by become the indexes of our grouped df \n",
    "#The groupby method returns a \"groupby object\" (can be a series.groupby.object or df.groupby.object)\n",
    "#Loads of aggregation boil down to min/max/count/sum etc\n",
    "#We can build a groupby object then select a series from a groupby object.  \n",
    "#Tips for transformation and aggregation \n",
    "#NO ITERATION RULE: If ever you start writing 'for smth in pandas_object': there's always a better way of doing it by using this pandas_object and apply a function: pandas_object.apply() \n",
    "#Hence: never explicitely iterate over pandas object, apply or aggregate instead\n",
    "#Apply or aggregate don't need arguments. We always need to think before applying: 'what would this argument of this function should be?' Should be a group df or a series.\n",
    "#ARGUMENT RULE: always think of the argument you would pass to the function.\n",
    "Group df by smth: df_grouped = old_df.groupby('city')\n",
    "Display groups: df_by_city = df.groupby('city') / by_city.groups #Returns a dictionarry with the cities as keys and indices of all the values belonging to this group as dict values\n",
    "Extract get stars mean by city: stars_by_city = df.groupby('city')['stars'].mean()\n",
    "Show methods aplicable to the groupby object: dir(grouped_df)\n",
    "Show mean for each group: grouped_df.mean()\n",
    "Retrieve particular group: grouped_df.get_group('Anthem') / df[df['city'] == 'Anthem']\n",
    "Aggregate and specify methods: agg_by_city = df.groupby('city').agg({'field1':{'mean':'mean', 'std':'std'}, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'review count':'sum', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'business_id':'count'})\n",
    "#Sorting the df \n",
    "#Don't forget that most operations return a copy of your df, not the df itself (unless properly specified)\n",
    "Sort df by values: df.sort_values('stars') #sorts by stars\n",
    "Sort df by index: df.set_index('business_id').sort_index()\n",
    "\n",
    "#Replace, join, merge \n",
    "\n",
    "\tReplace states by code of state: #1/ for each state, associate code with zip 2/ replace in the df \n",
    "\tstate_abbr = dict(zip(census['state'].unique(), [list_of_codes]))\n",
    "\tcensus['state'] = census['state'].replace(state_abbr)\n",
    "\n",
    "\tRemove last word from city name: \n",
    "\tcensus['city'] = census['city'].apply(lambda x: ' '.join(x.split(' ')[:-1])) #pcq on vire le dernier mot\n",
    "\n",
    "\tMerge dfs on two columns:\n",
    "\tmerged_df = df.merge(census, on = ['state','city'], [how = inner, outer, left, right]) #by default, inner \n",
    "\n",
    "\tAdd a bunch of new rows\n",
    "\tnew_df = pd.concat([df1,df2]) #must have the same nb of fields\n",
    "\n",
    "#Working with time series \n",
    "#There's an example of read html in the notebook \n",
    "#Options for resempling include: mean, median, sum, last, first\n",
    "#Changing frequencies:\n",
    "Downsample data / Group rows based on datetime index: df.resample('10AS').mean() #Exactly like a groupby on datetime index: group by 10Y + SPECIFY THE METHOD to group by (here: mean all data for 10Y)\n",
    "Upsample data: df.resample('10').bfill() / df.resample('10').ffill() #Need bfill or ffill since we don't have data for each quarter = we have to tell pandas how to fill the missing values\n",
    "#All these capabilities are built on pandas timestamp class / pd.Timestapmt('January 8, 2017')\n",
    "Select data between two dates: pd.Timestamp('Feb. 11 2016 2:30 am') - pd.Timestamp('2015-08-03 5:13pm') #Note that timestamp will try to adapt these timestamp to the actual time format \n",
    "Find indexes between two dates and specify frequency: pd.date_range(start = '1/8/2017', end='3/2/2017', freq = '8') #One record every 8 other days\n",
    "Find data with specific timestamp using offset: \n",
    "\n",
    "\tfrom pandas.tseries.offsets import BDay, Day, BMonthEnd\n",
    "\ta = pd.Timestamp('January 9, 2017') - Day(4) #Find data recorded on 4rth day before\n",
    "\tb = pd.Timestamp('January 9, 2017') - BDay(4)# 4 business days before\n",
    "\tc = pd.Timestamp('January 9, 2017') + BMonthEnd(4) #4 days before month's end\n",
    "\n",
    "Quick histogram to show frequencies: df['review_count'].apply(np.log).hist(bins = 30)\n",
    "Quick plot with pandas: pd['Annual Growth Rate'].plot() #See pandas doc on visualization \n",
    "\n",
    "#Confidence Intervals (Central Limit Theorem for parameter estimation)\n",
    "# If I center my CL distribution on my sample mean, I can calculate how far to either side I need to go to capture 95% of the probability (that the true mean is inside?) Then, there's only 2.5% probability that the true mean is right outside of that range\n",
    "# Testing hypothesis with confidence intervals: details to check: one-sided or two-sided tests   \n",
    "# How did we compute the confidence interval: \n",
    "# So you need to replace the x by (1+alpha)/2 to get two-sided test bound. Those bounds are essentially z-scores\n",
    "sp.stats.norm.ppf(x) returns the critical point where captured area < x (x 0.01 for 1% of the area...) \n",
    "            \n",
    "#SCIPY\n",
    "#what does scipy: calculus, numerical derivatives, integrals, lognormal distrib (sp.stats.lognorm(1,loc=20, scale = 25))\n",
    "# Scipy: library for data-processing and system-prototyping similar to Matlab, SciLab. \n",
    "import numpy as np, matplotlib as mpl, matplotlib.pyplot as plt \n",
    "Find documentation about scipy: np.info(optimize.fmin) # Use numpy help\n",
    "Find available methods: dir(optimize)\n",
    "Scipy subpackages: must be imported separately  / from scipy import linalg, optimize \n",
    "                     \n",
    "    Subpackages: \n",
    "    cluster - clustering algorithms\n",
    "    constants - physical and mathematical constants \n",
    "    fftpack - fast fourier transforms \n",
    "    integrate - integration and ordinary differential equation solvers \n",
    "    interpolate - interpolation and smoothing splines \n",
    "    io - input output\n",
    "    linalg - linear algebra \n",
    "    ndimage - ndimensional image processing \n",
    "    odr - orthogonal distance regression \n",
    "    optimize - optimization and root-finding routines \n",
    "    spatial - spatial dstructures and algos \n",
    "    special - special functions \n",
    "    stats - statistical distributions and functions \n",
    "\n",
    "#Index tricks: scipy works on arrays & it's highly encouraged to make use of some slicing tools to quickly build arrays\n",
    "#10j = reference to the step size in the slicing syntax (real number)\n",
    "Array slicers: np.mgrid, np.ogrid, np.r_, np.c_\n",
    "Create arrays using slicers: a = np.r_[3, [0]*5, -1:1:10j] / a = np.concatenate (([3], [0]*5, np.arange(-1, 1.002, 2/9.0))) #note the use of [] and : \n",
    "# r = for row concatenation - if the objects between the two , are 2-dimensional they will be stacked by rows and thus, must have the same nb of columns\n",
    "# c = same for columns (must have the same nb of rows)\n",
    "# mgrid = to produce N-dimensional arrays, possibility to use complex numbers as step size \n",
    "\n",
    "        >>> np.mgrid[0:5:4j,0:5:4j]\n",
    "                     \n",
    "        array([[[ 0.    ,  0.    ,  0.    ,  0.    ],\n",
    "                [ 1.6667,  1.6667,  1.6667,  1.6667],\n",
    "                [ 3.3333,  3.3333,  3.3333,  3.3333],\n",
    "                [ 5.    ,  5.    ,  5.    ,  5.    ]],\n",
    "               [[ 0.    ,  1.6667,  3.3333,  5.    ],\n",
    "                [ 0.    ,  1.6667,  3.3333,  5.    ],\n",
    "                [ 0.    ,  1.6667,  3.3333,  5.    ],\n",
    "                [ 0.    ,  1.6667,  3.3333,  5.    ]]])\n",
    "\n",
    "Polynomials with poly1d (numpy): p = poly1D([root 1, root 2, cste]) #Accepts coefficients/poly roots to create a polynomial, that can be integrated, differentiated, evaluated \n",
    "# In this case returns 1x + 2x + cste\n",
    "Integrate a poly: p.integ(k = 6) \n",
    "Derivate a poly: p.deriv() # returns formula\n",
    "Polynomial with arrays: p([4,5]) # The first element of the array gives the coefficient of the highest power - explicit functions to add/substract/multiply/integrate... \n",
    "Vectorizing functions: np.vectorize(custom_function) converts ordinary python function accepting scalars/returning scalars into a vectorized-function similar to numpy Ufuncs \n",
    "# Point: being able to use the custom function directly on arrays (considered element by element) \n",
    "                     \n",
    "    Vectorizing functions\n",
    "    # Note that the following function could have been written in vector form wiithout the use of vectorize\n",
    "    # But most finctions that employ optimization or integration routines can only be vectorized using \"vectorize\"\n",
    "    def addsubstract(a,b): \n",
    "        if a>b: \n",
    "            return a-b \n",
    "        else: \n",
    "            return b-a\n",
    "    vec_addsubstract = np.vectorize(addsubstract)\n",
    "    vec_addsubstract([0,3,6,9],[1,3,5,7])\n",
    "       \n",
    "Type handling: np.iscomplex / np.isreal / np.iscomplexobj / np.isrealobj # Former return array of 0/1 - Latter return a scalar describing result of test on the entire object \n",
    "Get real part of object: np.real \n",
    "Get imaginary part of object: np.imag # for anything that can be turned into a numpya rray \n",
    "Turn imag to real if relevant: np.real_if_close: turns complex value into  real if the imaginary part is tiny \n",
    "Check if scalar: np.isscalar\n",
    "Select el in arrays based on list of conditions: np.select(condlist, choicelist) # condlist = [x<3, x>5] | choicelist = [x, x**2] | returns array \n",
    "Scipy.special package: for factorial and comb function \n",
    "Integration methods: use scipy.integrate.quad(lambda x: function(x), start, end) / check help(integrate) for alternative integration methods (gaussian, romberg)\n",
    "\n",
    "#SCIPY.STATS\n",
    "# Over 80 continuous random variables  and 10 discrete have been implemented using these classes \n",
    "# All distribs are brought with relevant doc: access with stats.function_name.__doc__ \n",
    "from scipy import stats \n",
    "Main public methodsd for continuous RVs: \n",
    "                     \n",
    "    rvs: random variates \n",
    "    pdf: probability density \n",
    "    cdf: comulative distribution function\n",
    "    sf: survival function (1-CDF) \n",
    "    ppf: percent point function (inverse of CDF)\n",
    "    isf: inverse survival function (inverse of SFs) \n",
    "    stats: returns mean, variance, fisher skew, fisher kurtosis \n",
    "    moment: non-central moment of the distribution \n",
    "\n",
    "Compute cdf at several points: RV_name.cdf([list_of_points_to_compute]) / norm.cdf(np.array([-1., 0, 1]) #All methods are vectorized \n",
    "Find the median of a distrib using ppf: norm.pff(0.5) \n",
    "Generate a sequence of random variates: norm.rvs(size = k) # k = nb of variates, returned as array \n",
    "Ensure reproductibility with a seed: np.random.seed(42) # but relying on a global state is not recommended though \n",
    "Ensure reproductibility of variates: norm.rvs(size = k, random_state = 42) # better tan rand seed #note: rorm.rvs(5) - pcq firs arg isn't 5 \n",
    "# Distrib parameters: all distribs take loc and scale as keyword parameters to adjust the location & scale of the distrib (for norm: loc = mean, scale = stdev)\n",
    "# Default values: loc = 0, scale = 1 \n",
    "# It is recommended to set loc and scale parameters explicitly, by passing the values as keywords rather than args \n",
    "# Repetition can be minimized by \"freezing the distrib\"\n",
    "Standardize distrib: (X - loc)/scale \n",
    "Scale exponential distrib to get mean at 1: given F(x) = 1 - exp(-lambda x), we need to take scale = 1./lambda \n",
    "from scipy.stats import expon | expon.mean(scale = 1./lambda)         \n",
    "Get mean of normally distributed echantillon: np.mean(norm.rvs(5, size = 500))\n",
    "Additional parameters (shape parameter alpha): needed to implement, for instance, the gamma distribution: \n",
    "                                                                                   \n",
    "                                                                                   \n",
    "        >>> from scipy.stats import gamma\n",
    "        >>> gamma.numargs\n",
    "        1\n",
    "        >>> gamma.shapes\n",
    "        'a'\n",
    "        >>> gamma(1, scale=2.).stats(moments=\"mv\")\n",
    "        (array(2.0), array(4.0))                                                                           \n",
    "                                                                                   \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "            \n",
    "                     \n",
    "\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "                     \n",
    "# SCIPY SPECIAL.............................\n",
    "# For bessel functions of real order \n",
    "# Cython bindings for special functionss (scipy.special.cython_special) \n",
    "# Functions not in scipy.special: binary entropy function / rectangular step function / ramp function (bc can be easily recreated + dispo on scipy doc)\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "\n",
    "#...........................................\n",
    "                     \n",
    "\n",
    "                     \n",
    "                     \n",
    "                    \n",
    "                     \n",
    "\n",
    "                     \n",
    "                     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
